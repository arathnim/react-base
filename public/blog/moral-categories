{"content":"<p>A <em>long</em> time ago, something called morality entered into human consiousness,\npresumably, beaten into our long-dead ancestors to enforce rules formerly backed only in violence.\nIt occupies a layer between our emotional reactions to certain decisions,\nand our actual ability to make decisions.\nDefined in a philosophic terms, it&#39;s a mental system used to determine the value of decisions,\nand thus, to make decisions.</p>\n<p>Of course, that&#39;s not quite the whole story;\nthere are strong emotional connotations involved with this value-assignment,\nhappiness and fullfillment when we live up to the ideals of our moral system,\ndisgust when actions contrary to it are performed.\nSuch systems are also social, in the sense that you use them to evaluate\nthe decisions of others, to determine the value of the person.</p>\n<p>Leaving aside the questions about how useful that particular assumption is,\nthe study of these systems (and the categories I already formed by describing them to you) falls under the purview of\nPhilosophy, this study being one of the pillars of the field.</p>\n<p>They have a lot of terminology to describe the things I&#39;m about to describe,\nnone of which I&#39;m going to use, in the interest of seperating the connotation from the definition.</p>\n<p>It should also be noted that the following little narrative is a complete fabrication.</p>\n<h2 id=\"storytime\">storytime</h2>\n<p>Philosophers, in their quest to understanding the nature of morality, started looking for patterns in moral systems.\nSo they formed an experimental procedure of sorts, a way to explore the moral systems of people,\nbased on asking questions on moral topics, such as killing or theft.</p>\n<p>&quot;Is killing wrong? What about soldiers? What about self-defense?&quot;</p>\n<p>&quot;Is theft wrong? Would you steal something if you really needed it? To feed your starving family?&quot;</p>\n<p>Based on these answers, they came up with a number of categories and subcategories, of which, for brevity&#39;s sake, I will only mention two.</p>\n<p>The first is the rule-makers, who tend to form simple rules in response to moral queries, and take actions which don&#39;t violate these rules:\n&quot;Killing is immoral, unless it&#39;s in self-defense.&quot;</p>\n<p>The second is the number-crunchers, who place values, usually numberical, on consequences, and compare them to determine what to do.\nThey look at the future where they don&#39;t act, and see five people dead, then look at the future where they do act,\nand see only one person dead. So they act.</p>\n<p>Ideas, once given names, rarely stay dormant.\nThe philosophers who studied that patterns incorperated them into their identities, becoming rule-makers and number-crunchers,\ntaking these systems as their own morals, played out like robots.\nThey argued, the rule-makers pointing out that the number-crunchers would commit atrocities to one in order to save the lives of two,\nand the number-crunchers responding by saying the rule-makers would sooner die of hunger than steal a loaf of bread.\nThrough this process, they refined their systems, creating categories upon categories, opining on guilt, blame, and responsibility,\nuntil the system was too convoluted for the unlearned to use or understand.</p>\n<h2 id=\"systemization\">systemization</h2>\n<p>In general, I have no problem with models of the same type as moral categories.\nFreud&#39;s theories of id, ego, and superego are, despite the dismal epistemology and disturbing familial aspects,\nextremely useful in helping humans understand the nature of the mind, which is largely the point of models.\nSame for the economic model of supply and demand curves or the point-masses of physics.\nI chose these examples because it&#39;s relatively easy to see that <em>they are not the thing they represent</em>,\nthe map is not the territory.</p>\n<p>This is easy to see in the &#39;cracks&#39; in the theories, as in <a href=\"https://en.wikipedia.org/wiki/Utility_monster\">Nozick&#39;s utility monster</a>,\nor the fact that utility calculations on the value of a human life don&#39;t usually take into account the value of that life to the person doing\nthe calculating, which leads to things like &quot;I have so internalized utility, I would sacrifice the life of my best friend to save two other people.&quot;\nOn the deontological side, the fact that people break moral rules all the time, which calls into question how useful they are anyway,\nand the fact that, when given a decision between two immoral actions, one will be chosen, which implies a partial ordering to moral rules.</p>\n<p>Remember the context in which these models were made.\nThe cracks are the places where the models falter and normal human decision making takes control.\nThey do not describe the entirety of human decision making, nor should they.\nNozick is merely pointing out a discrepency between how the model would work if you programmed some robots to go by it alone, and how humans actually behave.\nNot that this kind of question isn&#39;t useful, in the proper context, but as a &quot;criticism of utilitaranism&quot;, not so much.\nThey seem more like &quot;gotchas&quot; than attempts to make distinctions or points about the system, or to advance it by building up the system.</p>\n<p>Essentially, this gives philosophers a new way to respond to such criticisms:\n&quot;yes, that could be used to refine the model, but it&#39;s too complicated to fit in the core theory&quot;, or\n&quot;this is too far on the usefulness/complexity curve to be worth teaching or learning about.&quot;\nHopefully, this will help refine the categories of moral philosophy somewhat,\nwhich are currently nebulous to the point they don&#39;t deserve to be called categories.\nIt&#39;s not like I want a whole hierarchy of useless information,\nbut a list of assumptions that define each category, e.g. &quot;this assumes you use the same moral standards for everyone&quot;,\n&quot;this only takes into account things which are both knowable and beneficial to society&quot;, would be extremely useful.</p>\n<p>If you&#39;re one of those people who thinks that following rules is good in and of itself,\nand want to build up actual rule systems, not categories, whatever man, just don&#39;t mix that up with the categories.\nAlso if you&#39;re trying to build up a literal human intelligence through algorithmic utility calculations.\nAs a side note, if you think the law follows such rules, and that&#39;s what makes it just, you have it completely backwards.\nLaws are largely composed of rules because it wouldn&#39;t make sense any other way, their role is to specify which actions are illegal,\nwhich is hard to do from the consequences alone, although such considerations do leak into sentencing; laws tend to follow moral rules\nbecause people are happy when the laws reflect their morals, and the rule of law exists to hold society together.</p>\n<p>More succinctly, I think it&#39;s possible to create moral categories that still allow for personal moral explanation,\nwithout pouring over every little detail that would be in a fully algorithmic system,\nand without thinking you need pick elements from only the rule-maker or number-cruncher side.\nIdeally, teaching that these systems were intented for different minds and historical contexts,\nwhile leaving room for rhetorical development.</p>\n","data":{"title":"The Usage of Moral Categories in Academic Philosophy","date":"November 5th, 2017"},"excerpt":""}